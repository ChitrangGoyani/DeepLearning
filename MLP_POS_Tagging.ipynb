{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7596086",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-17 09:14:59.828201: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-17 09:15:00.021751: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-17 09:15:00.021768: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-17 09:15:01.770312: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-17 09:15:01.770591: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-17 09:15:01.770599: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from gensim.models import FastText\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Flatten, BatchNormalization, Dropout, Input, Activation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
    "from keras.utils import np_utils\n",
    "from numpy.random import seed\n",
    "import math, nltk, random, keras\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d89f835e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package conll2000 to\n",
      "[nltk_data]     /home/chitrang/nltk_data...\n",
      "[nltk_data]   Package conll2000 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('conll2000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "523f9cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import conll2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15e5a015",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = list(conll2000.tagged_sents(tagset='universal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9310de99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tagged sentences in dataset:  10948\n",
      "Tagged words in dataset: 259104\n"
     ]
    }
   ],
   "source": [
    "print(\"Tagged sentences in dataset: \", len(dataset))\n",
    "print(\"Tagged words in dataset:\", len([item for sublist in dataset for item in sublist]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c602b913",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_sequence(sentences):\n",
    "    return [[t for w, t in sentence] for sentence in sentences]\n",
    "\n",
    "def text_sequence(sentences):\n",
    "    return [[w for w, t in sentence] for sentence in sentences]\n",
    "def untag(tagged_sentence):\n",
    "    return [w for w, _ in tagged_sentence]\n",
    "\n",
    "def untag_pos(tagged_sentence):\n",
    "    return [t for _, t in tagged_sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62af8d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "embs_path = '/home/chitrang/Downloads/wiki-news-300d-1M.vec'\n",
    "embeddings = KeyedVectors.load_word2vec_format(embs_path, binary=False)\n",
    "dim = embeddings.vectors.shape[1]\n",
    "pad = np.zeros(dim)\n",
    "np.random.seed(3)\n",
    "oov = np.random.uniform(-0.25, 0.25, dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d57c75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_embs(sentence, index, window=2):\n",
    "    unknown=0\n",
    "    vec = np.array([])\n",
    "    for i in range(index-window, index+window+1):\n",
    "#         if i < 0:\n",
    "#             vec = np.append(vec, pad)\n",
    "#         if i > len(sentence)-1:\n",
    "#             vec = np.append(vec, pad)\n",
    "        try:\n",
    "            vec = np.append(vec, embeddings[sentence[i]])\n",
    "        except:\n",
    "            vec = np.append(vec, oov)\n",
    "            unknown += 1\n",
    "    return vec, unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f738de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_dataset(tagged_sentences, window):\n",
    "    i=0\n",
    "    X, y = [], []\n",
    "    for doc_index, tagged in enumerate(tagged_sentences):\n",
    "        for index in range(len(tagged)):\n",
    "            X.append(features_embs(untag(tagged), index, window)[0])\n",
    "            y.append(tagged[index][1])\n",
    "            k = features_embs(untag(tagged), index, window)[1]\n",
    "            i += k\n",
    "    return X, y, i\n",
    "\n",
    "def transform_test_sentence(sentence, window):\n",
    "    X = []\n",
    "    for index in range(len(sentence)):\n",
    "            X.append(features_embs(sentence, index, window))\n",
    "    return X\n",
    "\n",
    "def vectorize(train, window=2):\n",
    "    X_train, y_train, unk_tr = transform_to_dataset(train, window=window)\n",
    "    X_train = [x for x in X_train]\n",
    "    X_train = np.asarray(X_train)\n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1fd8428",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = vectorize(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9944a01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset split: Train - Validation - Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "715f8866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(209873, 1500) (23320, 1500) (25911, 1500)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_val.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cabe7ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.', 'ADJ', 'ADP', 'ADV', 'CONJ', 'DET', 'NOUN', 'NUM', 'PRON', 'PRT', 'VERB', 'X']\n"
     ]
    }
   ],
   "source": [
    "classes = sorted(list(set(y_train)))\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f62c2702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(209873, 12)\n"
     ]
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_val = le.transform(y_val)\n",
    "y_train = keras.utils.to_categorical(y_train)\n",
    "y_val = keras.utils.to_categorical(y_val)\n",
    "y_test = le.transform(y_test)\n",
    "y_test = keras.utils.to_categorical(y_test)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa656654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               768512    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                32832     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 12)                780       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 802,124\n",
      "Trainable params: 802,124\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-17 09:19:38.329325: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-17 09:19:38.329514: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-17 09:19:38.329571: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-17 09:19:38.329837: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-17 09:19:38.329879: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2023-03-17 09:19:38.329915: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2023-03-17 09:19:38.329948: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-17 09:19:38.330223: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-17 09:19:38.330463: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-03-17 09:19:38.330471: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-03-17 09:19:38.330727: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(512, activation='relu', input_dim=X_train.shape[1]))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf695e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epoch = 7\n",
    "batch_size = 128\n",
    "early_stopping = EarlyStopping(monitor = 'val_accuracy', patience = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1448b654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-17 09:22:23.416992: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1259238000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1640/1640 [==============================] - 17s 10ms/step - loss: 0.2660 - accuracy: 0.9209 - val_loss: 0.0834 - val_accuracy: 0.9756\n",
      "Epoch 2/7\n",
      "1640/1640 [==============================] - 16s 10ms/step - loss: 0.1058 - accuracy: 0.9686 - val_loss: 0.0681 - val_accuracy: 0.9797\n",
      "Epoch 3/7\n",
      "1640/1640 [==============================] - 19s 12ms/step - loss: 0.0819 - accuracy: 0.9750 - val_loss: 0.0659 - val_accuracy: 0.9791\n",
      "Epoch 4/7\n",
      "1640/1640 [==============================] - 20s 12ms/step - loss: 0.0678 - accuracy: 0.9791 - val_loss: 0.0597 - val_accuracy: 0.9824\n",
      "Epoch 5/7\n",
      "1640/1640 [==============================] - 19s 11ms/step - loss: 0.0589 - accuracy: 0.9817 - val_loss: 0.0615 - val_accuracy: 0.9818\n",
      "Epoch 6/7\n",
      "1640/1640 [==============================] - 19s 11ms/step - loss: 0.0512 - accuracy: 0.9837 - val_loss: 0.0601 - val_accuracy: 0.9820\n",
      "Epoch 7/7\n",
      "1640/1640 [==============================] - 18s 11ms/step - loss: 0.0460 - accuracy: 0.9852 - val_loss: 0.0647 - val_accuracy: 0.9826\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=nb_epoch,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=1,\n",
    "                    callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9969e734",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"mlp_model.h5\", save_format='h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "72574a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"mlp_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "42bbfaf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch index: 6\n"
     ]
    }
   ],
   "source": [
    "best_epoch = history.history['val_accuracy'].index(max(history.history['val_accuracy']))\n",
    "print('Best epoch index:', best_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d8cabf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "810/810 [==============================] - 2s 2ms/step - loss: 0.0662 - accuracy: 0.9824\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "117eff4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25911/25911 [==============================] - 24s 907us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test, batch_size=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0310fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9824\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: {0:.4f}\".format(scores[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57aca30",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c0772e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
